{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35692416",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20043c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft,dct\n",
    "import librosa\n",
    "from scipy import signal\n",
    "import soundfile as sf\n",
    "from librosa.display import specshow\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e099d97",
   "metadata": {},
   "source": [
    "Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # separate \n",
    "\n",
    "carTrain = glob.glob(\"cars/train/*.wav\")\n",
    "carTest = glob.glob(\"cars/test/*.wav\")\n",
    "\n",
    "tramTrain = glob.glob(\"trams/train/*.wav\")\n",
    "tramTest = glob.glob(\"trams/test/*.wav\")\n",
    "\n",
    "dataset=[]\n",
    "labels = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importFiles(files, label):\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    for file in files:\n",
    "        data,sr = librosa.load(file)\n",
    "        data = librosa.effects.trim(data, top_db=20, frame_length=1024, hop_length=512)[0] \n",
    "        # print(data.size)\n",
    "        # print(data.shape)# Desired length in samples\n",
    "        desired_length = sr * 5\n",
    "        # # Initialize a new array of zeros with the desired length\n",
    "        fixed_length_data = np.zeros(desired_length)\n",
    "        #  Check the length of the original data\n",
    "        original_length = len(data)\n",
    "        # # If original data is longer than desired length, truncate it\n",
    "        # # If it is shorter, pad with zeros\n",
    "        if original_length > desired_length:\n",
    "            fixed_length_data = data[:desired_length]\n",
    "        else:\n",
    "            fixed_length_data[:original_length] = data\n",
    "        # # Now use fixed_length_data as your adjusted data\n",
    "        data = fixed_length_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        labels.append(label)\n",
    "        dataset.append(data)\n",
    "\n",
    "    return dataset,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_289696/3366563929.py:5: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  data,sr = librosa.load(file)\n",
      "/home/smitty/miniconda3/envs/audioproc/lib/python3.8/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "# # separate\n",
    "\n",
    "car_dataset, car_label  = importFiles(carTrain, 0)\n",
    "car_test_dataset, car_test_label = importFiles(carTest, 0)\n",
    "tram_dataset, tram_label = importFiles(tramTrain, 1)\n",
    "tram_test_dataset, tram_test_label = importFiles(tramTest, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tram_dataset_array = np.array(tram_dataset)\n",
    "car_dataset_array = np.array(car_dataset)\n",
    "tram_label_array = np.array(tram_label)\n",
    "car_label_array = np.array(car_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db950037",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.concatenate([tram_dataset, car_dataset], axis=0)\n",
    "labels = np.concatenate([tram_label, car_label], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4880df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = np.concatenate([tram_test_dataset,car_test_dataset], axis=0)\n",
    "labels_test = np.concatenate([tram_test_label, car_test_label], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9597e96a",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(data, target_height, target_width):\n",
    "    h = data.shape[0]\n",
    "    w = data.shape[1]\n",
    "    \n",
    "    a = max((target_height - h) // 2,0)\n",
    "    aa = max(0,target_height - a - h)\n",
    "    \n",
    "    b = max(0,(target_width - w) // 2)\n",
    "    bb = max(target_width - b - w,0)\n",
    "    \n",
    "    return np.pad(data, pad_width=((a, aa), (b, bb)), mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f78ff240",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 44000\n",
    "f2=[]\n",
    "\n",
    "def extractFeatures(dataset, model):\n",
    "    features = []\n",
    "    max_size = 1000\n",
    "    \n",
    "    for audio in dataset:\n",
    "        mfccs = librosa.feature.mfcc(y=np.asarray(audio), sr=fs, n_mfcc=50)\n",
    "    \n",
    "        # spectral spread\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "        # spectral energy\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "        # spectral density\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "        #  rate of sign-changes in the signal\n",
    "        zerocrossing_rate = librosa.feature.zero_crossing_rate(y=np.asarray(audio))\n",
    "\n",
    "        #  frequency below which a certain percentage of the power spectrum is concentrated\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=np.asarray(audio), sr=fs)\n",
    "        \n",
    "        # combined_features = np.hstack([np.mean(mfccs, axis=1), np.std(mfccs, axis=1),\n",
    "        #                                np.mean(spectral_bandwidth), np.std(spectral_bandwidth),\n",
    "        #                                np.mean(spectral_centroid), np.std(spectral_centroid),\n",
    "        #                                np.mean(spectral_contrast), np.std(spectral_contrast),\n",
    "        #                                np.mean(zerocrossing_rate), np.std(zerocrossing_rate),\n",
    "        #                                np.mean(spectral_rolloff), np.std(spectral_rolloff)])\n",
    "        \n",
    "        # combined_features_for_CNN = np.hstack([spectral_bandwidth, spectral_centroid])\n",
    "        # combined_features_for_CNN2= np.hstack([zerocrossing_rate, spectral_rolloff])\n",
    "        # combined_features2=np.vstack([combined_features_for_CNN,combined_features_for_CNN2])\n",
    "\n",
    "        if model == \"KNN1\":\n",
    "            # combined features include spectral bandwidth, spectral centroid, zero-crossing rate, spectral rolloff\n",
    "            mfccs = np.reshape(mfccs, (1,-1))\n",
    "            spectral_contrast = np.reshape(spectral_contrast, (1,-1))\n",
    "            combined_features = np.hstack([spectral_bandwidth, spectral_centroid, zerocrossing_rate, spectral_rolloff, mfccs, spectral_contrast])\n",
    "            features.append(combined_features)\n",
    "        elif model == \"KNN2\":\n",
    "            mfccs = np.reshape(mfccs, (1,-1))\n",
    "            spectral_contrast = np.reshape(spectral_contrast, (1,-1))\n",
    "            combined_features = np.hstack([spectral_bandwidth, spectral_centroid, spectral_rolloff, mfccs])\n",
    "            features.append(combined_features)\n",
    "        else:\n",
    "            combined_features = np.vstack([padding(spectral_bandwidth, 1, max_size),\n",
    "                                           padding(spectral_centroid, 1, max_size),\n",
    "                                           padding(zerocrossing_rate, 1, max_size), \n",
    "                                           padding(spectral_rolloff, 1, max_size),\n",
    "                                           padding(spectral_contrast, 1, max_size)])\n",
    "            for i in range(0,mfccs.shape[0]):\n",
    "                combined_features = np.append(combined_features, padding(spectral_bandwidth, 1, max_size), axis=0)\n",
    "                combined_features = np.append(combined_features, padding(spectral_centroid, 1, max_size), axis=0)\n",
    "                combined_features = np.append(combined_features, padding(zerocrossing_rate, 1, max_size), axis=0)\n",
    "                combined_features = np.append(combined_features, padding(spectral_rolloff, 1, max_size), axis=0)\n",
    "                combined_features = np.append(combined_features, padding(spectral_contrast, 1, max_size), axis=0)\n",
    "            \n",
    "                if combined_features.shape[0] > mfccs.shape[0]:\n",
    "                    difference = combined_features.shape[0] - mfccs.shape[0]\n",
    "                    combined_features = combined_features[:-difference, :]\n",
    "                    break\n",
    "                \n",
    "                \n",
    "            combined_features = np.dstack((combined_features, padding(mfccs, mfccs.shape[0], max_size)))\n",
    "            \n",
    "            features.append(combined_features)\n",
    "\n",
    "    features = np.array(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06f3f159",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = extractFeatures(dataset, \"KNN1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features2 = extractFeatures(dataset,\"KNN2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n",
      "146\n"
     ]
    }
   ],
   "source": [
    "print(len(features))\n",
    "print(len(features2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d269ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = extractFeatures(dataset_test,\"KNN1\")\n",
    "features_test2 = extractFeatures(dataset_test,\"KNN2\")\n",
    "# features_test2=extractFeatures(dataset_test,\"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fs = 44000\n",
    "# features=[]\n",
    "# features2=[]\n",
    "# f2=[]\n",
    "\n",
    "# for audio in dataset:\n",
    "#     mfcc = librosa.feature.mfcc(y=np.asarray(audio), sr=fs, n_mfcc=50)    \n",
    "#     # spectral spread\n",
    "#     spectral_bandwidth = librosa.feature.spectral_bandwidth(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "#     # spectral energy\n",
    "#     spectral_centroid = librosa.feature.spectral_centroid(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "#     # spectral density\n",
    "#     spectral_contrast = librosa.feature.spectral_contrast(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "#     #  rate of sign-changes in the signal\n",
    "#     zerocrossing_rate = librosa.feature.zero_crossing_rate(y=np.asarray(audio))\n",
    "\n",
    "#     #  frequency below which a certain percentage of the power spectrum is concentrated\n",
    "#     spectral_rolloff = librosa.feature.spectral_rolloff(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "#     combined_features = np.hstack([np.mean(mfcc, axis=1), np.std(mfcc, axis=1),\n",
    "#                                    np.mean(spectral_bandwidth), np.std(spectral_bandwidth),\n",
    "#                                    np.mean(spectral_centroid), np.std(spectral_centroid),\n",
    "#                                    np.mean(spectral_contrast), np.std(spectral_contrast),\n",
    "#                                    np.mean(zerocrossing_rate), np.std(zerocrossing_rate),\n",
    "#                                    np.mean(spectral_rolloff), np.std(spectral_rolloff)])\n",
    "    \n",
    "#     combined = np.hstack([spectral_bandwidth, spectral_centroid])\n",
    "#     combo= np.hstack([zerocrossing_rate, spectral_rolloff])\n",
    "#     co=np.vstack([combined,combo])\n",
    "#     f2.append(co)\n",
    "\n",
    "#     # #combined = np.concatenate(mfcc,spectral_bandwidth, spectral_centroid, spectral_contrast, zerocrossing_rate, spectral_rolloff)\n",
    "#     # x=spectral_bandwidth.shape\n",
    "\n",
    "#     combined_features_2d = combined_features.reshape(1, -1)\n",
    "\n",
    "#     # Append combined features as 2D array\n",
    "#     features.append(combined_features_2d)\n",
    "#     #features2.append(f2)\n",
    "\n",
    "#     #features.append(combined_features)\n",
    "#     features2.append(mfcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "705f2159",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.asarray(features)\n",
    "features2 = np.asarray(features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a09b0bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test= np.asarray(features_test)\n",
    "features_test2= np.asarray(features_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "251f99cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 1, 13176)\n",
      "(146, 1, 11448)\n",
      "(36, 1, 13176)\n",
      "(36, 1, 11448)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(features2.shape)\n",
    "\n",
    "print(features_test.shape)\n",
    "print(features_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 13176)\n",
      "(146, 11448)\n"
     ]
    }
   ],
   "source": [
    "features_knn = features.reshape((features.shape[0],-1))\n",
    "features_knn2 = features2.reshape((features2.shape[0],-1))\n",
    "\n",
    "print(features_knn.shape)\n",
    "print(features_knn2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test_knn = features_test.reshape((features_test.shape[0],-1))\n",
    "features_test_knn2 = features_test2.reshape((features_test2.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 13176)\n",
      "(36, 11448)\n"
     ]
    }
   ],
   "source": [
    "print(features_test_knn.shape)\n",
    "print(features_test_knn2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af3a66b",
   "metadata": {},
   "source": [
    "Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7647058823529411\n",
      "0.8125\n",
      "0.8055555555555556\n"
     ]
    }
   ],
   "source": [
    "# # first knn\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(features_knn, labels)\n",
    "\n",
    "y_pred = knn.predict(features_test_knn)\n",
    "\n",
    "precision = precision_score(labels_test, y_pred)\n",
    "recall = recall_score(labels_test, y_pred)\n",
    "accuracy = accuracy_score(labels_test, y_pred)\n",
    "\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7647058823529411\n",
      "0.8125\n",
      "0.8055555555555556\n"
     ]
    }
   ],
   "source": [
    "# X_train2, X_test2, y_train2, y_test2 = train_test_split(features3, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "knn2 = KNeighborsClassifier(n_neighbors=1)\n",
    "knn2.fit(features_knn2, labels)\n",
    "\n",
    "y_pred2 = knn2.predict(features_test_knn2)\n",
    "\n",
    "precision2 = precision_score(labels_test, y_pred2)\n",
    "recall2 = recall_score(labels_test, y_pred2)\n",
    "accuracy2 = accuracy_score(labels_test, y_pred2)\n",
    "\n",
    "print(precision2)\n",
    "print(recall2)\n",
    "print(accuracy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03402f72",
   "metadata": {},
   "source": [
    "### CNN\n",
    "#### This section is no longer used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "a3df585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "c2195ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_20 (Conv2D)          (None, 49, 999, 4)        20        \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 195804)            0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 16)                3132880   \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3133045 (11.95 MB)\n",
      "Trainable params: 3133045 (11.95 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## original model\n",
    "# input_shape = (2, 432, 1)\n",
    "input_shape = (50,1000,1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(4, kernel_size=(2,2), activation='relu', input_shape=input_shape))\n",
    "#model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_16 (Conv2D)          (None, 48, 998, 32)       608       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 24, 499, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 24, 499, 32)       0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 22, 497, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 11, 248, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 11, 248, 64)       0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 9, 246, 32)        18464     \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 70848)             0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 64)                4534336   \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4574801 (17.45 MB)\n",
      "Trainable params: 4574801 (17.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## alternative model\n",
    "input_shape = (50,1000,2)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(24, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features2, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "89feff4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/smitty/miniconda3/envs/audioproc/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/smitty/miniconda3/envs/audioproc/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/smitty/miniconda3/envs/audioproc/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/smitty/miniconda3/envs/audioproc/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/smitty/miniconda3/envs/audioproc/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/smitty/miniconda3/envs/audioproc/lib/python3.8/site-packages/keras/src/engine/input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_15' (type Sequential).\n    \n    Input 0 of layer \"conv2d_20\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 50, 1000, 2)\n    \n    Call arguments received by layer 'sequential_15' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 50, 1000, 2), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/smitty/Dropbox/study/intro to audio proc 2/audio/project.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/smitty/Dropbox/study/intro%20to%20audio%20proc%202/audio/project.ipynb#Y101sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mfeatures2,y\u001b[39m=\u001b[39;49mlabels,batch_size\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/audioproc/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file0l_q3tnn.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/smitty/miniconda3/envs/audioproc/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/smitty/miniconda3/envs/audioproc/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/smitty/miniconda3/envs/audioproc/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/smitty/miniconda3/envs/audioproc/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/smitty/miniconda3/envs/audioproc/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/smitty/miniconda3/envs/audioproc/lib/python3.8/site-packages/keras/src/engine/input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_15' (type Sequential).\n    \n    Input 0 of layer \"conv2d_20\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 50, 1000, 2)\n    \n    Call arguments received by layer 'sequential_15' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 50, 1000, 2), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=features2,y=labels,batch_size=5,epochs=10,validation_split=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c3e8a020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "output= model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7776344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "predictions = [1 if x > 0.5 else 0 for x in output]\n",
    "\n",
    "accuracy2 = accuracy_score(labels_test, predictions)\n",
    "precision2 = precision_score(labels_test, predictions)\n",
    "recall2 = recall_score(labels_test, predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9759d590",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0936b1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbour:\n",
      "Precision: 0.8461538461538461\n",
      "Recall: 0.6111111111111112\n",
      "CNN:\n",
      "Accuracy: 0.4444444444444444\n",
      "Precision: 0.4444444444444444\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Nearest Neighbour:\")\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "print(\"CNN:\")\n",
    "print(\"Accuracy:\", accuracy2)\n",
    "print(\"Precision:\", precision2)\n",
    "print(\"Recall:\", recall2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
