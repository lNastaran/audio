{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "20043c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft,dct\n",
    "import librosa\n",
    "from scipy import signal\n",
    "import soundfile as sf\n",
    "from librosa.display import specshow\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # separate \n",
    "\n",
    "carTrain = glob.glob(\"cars/train/*.wav\")\n",
    "carTest = glob.glob(\"cars/test/*.wav\")\n",
    "\n",
    "tramTrain = glob.glob(\"trams/train/*.wav\")\n",
    "tramTest = glob.glob(\"trams/test/*.wav\")\n",
    "\n",
    "dataset=[]\n",
    "labels = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importFiles(files, label):\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    for file in files:\n",
    "        data,sr = librosa.load(file)\n",
    "        data = librosa.effects.trim(data, top_db=20, frame_length=1024, hop_length=512)[0] \n",
    "        # print(data.size)\n",
    "        # print(data.shape)# Desired length in samples\n",
    "        desired_length = sr * 5\n",
    "        # # Initialize a new array of zeros with the desired length\n",
    "        fixed_length_data = np.zeros(desired_length)\n",
    "        #  Check the length of the original data\n",
    "        original_length = len(data)\n",
    "        # # If original data is longer than desired length, truncate it\n",
    "        # # If it is shorter, pad with zeros\n",
    "        if original_length > desired_length:\n",
    "            fixed_length_data = data[:desired_length]\n",
    "        else:\n",
    "            fixed_length_data[:original_length] = data\n",
    "        # # Now use fixed_length_data as your adjusted data\n",
    "        data = fixed_length_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        labels.append(label)\n",
    "        dataset.append(data)\n",
    "\n",
    "    return dataset,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # separate\n",
    "\n",
    "car_dataset, car_label  = importFiles(carTrain, 0)\n",
    "car_test_dataset, car_test_label = importFiles(carTest, 0)\n",
    "tram_dataset, tram_label = importFiles(tramTrain, 1)\n",
    "tram_test_dataset, tram_test_label = importFiles(tramTest, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "tram_dataset_array = np.array(tram_dataset)\n",
    "car_dataset_array = np.array(car_dataset)\n",
    "tram_label_array = np.array(tram_label)\n",
    "car_label_array = np.array(car_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 110250)\n",
      "(7, 110250)\n",
      "(8,)\n",
      "(7,)\n"
     ]
    }
   ],
   "source": [
    "print(tram_dataset_array.shape)\n",
    "print(car_dataset_array.shape)\n",
    "print(tram_label_array.shape)\n",
    "print(car_label_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fs = 44000\n",
    "# def extractFeatures(dataset):\n",
    "#     features=[]\n",
    "#     for audio in dataset:\n",
    "#         mfccs = librosa.feature.mfcc(y=np.asarray(audio), sr=fs, n_mfcc=40)\n",
    "#         features.append(mfccs)\n",
    "    \n",
    "#         # spectral spread\n",
    "#         spectral_bandwidth = librosa.feature.spectral_bandwidth(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "#         # spectral energy\n",
    "#         spectral_centroid = librosa.feature.spectral_centroid(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "#         # spectral density\n",
    "#         spectral_contrast = librosa.feature.spectral_contrast(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "#         #  rate of sign-changes in the signal\n",
    "#         zerocrossing_rate = librosa.feature.zero_crossing_rate(y=np.asarray(audio))\n",
    "\n",
    "#         #  frequency below which a certain percentage of the power spectrum is concentrated\n",
    "#         spectral_rolloff = librosa.feature.spectral_rolloff(y=np.asarray(audio), sr=fs)\n",
    "#         combined_features = np.hstack([np.mean(mfccs, axis=1), np.std(mfccs, axis=1),\n",
    "#                                        np.mean(spectral_bandwidth), np.std(spectral_bandwidth),\n",
    "#                                        np.mean(spectral_centroid), np.std(spectral_centroid),\n",
    "#                                        np.mean(spectral_contrast), np.std(spectral_contrast),\n",
    "#                                        np.mean(zerocrossing_rate), np.std(zerocrossing_rate),\n",
    "#                                        np.mean(spectral_rolloff), np.std(spectral_rolloff)])\n",
    "\n",
    "#         # features list\n",
    "#         features.append(combined_features)\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car_dataset=extractFeatures(car_dataset_array)\n",
    "# tram_dataset=extractFeatures(tram_dataset_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.concatenate([tram_dataset, car_dataset], axis=0)\n",
    "labels = np.concatenate([tram_label, car_label], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 110250)\n",
      "(15,)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 44000\n",
    "features=[]\n",
    "\n",
    "\n",
    "for audio in dataset:\n",
    "    mfccs = librosa.feature.mfcc(y=np.asarray(audio), sr=fs, n_mfcc=40)    \n",
    "    # spectral spread\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "    # spectral energy\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "    # spectral density\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "    #  rate of sign-changes in the signal\n",
    "    zerocrossing_rate = librosa.feature.zero_crossing_rate(y=np.asarray(audio))\n",
    "\n",
    "    #  frequency below which a certain percentage of the power spectrum is concentrated\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=np.asarray(audio), sr=fs)\n",
    "    combined_features = np.hstack([np.mean(mfccs, axis=1), np.std(mfccs, axis=1),\n",
    "                                   np.mean(spectral_bandwidth), np.std(spectral_bandwidth),\n",
    "                                   np.mean(spectral_centroid), np.std(spectral_centroid),\n",
    "                                   np.mean(spectral_contrast), np.std(spectral_contrast),\n",
    "                                   np.mean(zerocrossing_rate), np.std(zerocrossing_rate),\n",
    "                                   np.mean(spectral_rolloff), np.std(spectral_rolloff)])\n",
    "\n",
    "    # features list\n",
    "    features.append(combined_features)\n",
    "    #features.append(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def flatten_features(features):\n",
    "#     flattened_features = []\n",
    "#     for feature in features:\n",
    "#         flattened = np.hstack([np.mean(feature, axis=1), np.std(feature, axis=1)])\n",
    "#         flattened_features.append(flattened)\n",
    "#     return flattened_features\n",
    "\n",
    "\n",
    "# flattened_features = flatten_features(features)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# flattened_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # separate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# # all\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
