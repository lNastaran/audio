{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35692416",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "20043c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft,dct\n",
    "import librosa\n",
    "from scipy import signal\n",
    "import soundfile as sf\n",
    "from librosa.display import specshow\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e099d97",
   "metadata": {},
   "source": [
    "Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # separate \n",
    "\n",
    "carTrain = glob.glob(\"cars/train/*.wav\")\n",
    "carTest = glob.glob(\"cars/test/*.wav\")\n",
    "\n",
    "tramTrain = glob.glob(\"trams/train/*.wav\")\n",
    "tramTest = glob.glob(\"trams/test/*.wav\")\n",
    "\n",
    "dataset=[]\n",
    "labels = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importFiles(files, label):\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    for file in files:\n",
    "        data,sr = librosa.load(file)\n",
    "        data = librosa.effects.trim(data, top_db=20, frame_length=1024, hop_length=512)[0] \n",
    "        # print(data.size)\n",
    "        # print(data.shape)# Desired length in samples\n",
    "        desired_length = sr * 5\n",
    "        # # Initialize a new array of zeros with the desired length\n",
    "        fixed_length_data = np.zeros(desired_length)\n",
    "        #  Check the length of the original data\n",
    "        original_length = len(data)\n",
    "        # # If original data is longer than desired length, truncate it\n",
    "        # # If it is shorter, pad with zeros\n",
    "        if original_length > desired_length:\n",
    "            fixed_length_data = data[:desired_length]\n",
    "        else:\n",
    "            fixed_length_data[:original_length] = data\n",
    "        # # Now use fixed_length_data as your adjusted data\n",
    "        data = fixed_length_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        labels.append(label)\n",
    "        dataset.append(data)\n",
    "\n",
    "    return dataset,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # separate\n",
    "\n",
    "car_dataset, car_label  = importFiles(carTrain, 0)\n",
    "car_test_dataset, car_test_label = importFiles(carTest, 0)\n",
    "tram_dataset, tram_label = importFiles(tramTrain, 1)\n",
    "tram_test_dataset, tram_test_label = importFiles(tramTest, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "tram_dataset_array = np.array(tram_dataset)\n",
    "car_dataset_array = np.array(car_dataset)\n",
    "tram_label_array = np.array(tram_label)\n",
    "car_label_array = np.array(car_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "db950037",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.concatenate([tram_dataset, car_dataset], axis=0)\n",
    "labels = np.concatenate([tram_label, car_label], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "e4880df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = np.concatenate([tram_test_dataset,car_test_dataset], axis=0)\n",
    "labels_test = np.concatenate([tram_test_label, car_test_label], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9597e96a",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f78ff240",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 44000\n",
    "f2=[]\n",
    "\n",
    "def extractFeatures(dataset,model):\n",
    "    features=[]\n",
    "    features2=[]\n",
    "    for audio in dataset:\n",
    "        mfccs = librosa.feature.mfcc(y=np.asarray(audio), sr=fs, n_mfcc=50)\n",
    "    \n",
    "        # spectral spread\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "        # spectral energy\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "        # spectral density\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "        #  rate of sign-changes in the signal\n",
    "        zerocrossing_rate = librosa.feature.zero_crossing_rate(y=np.asarray(audio))\n",
    "\n",
    "        #  frequency below which a certain percentage of the power spectrum is concentrated\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=np.asarray(audio), sr=fs)\n",
    "        \n",
    "        combined_features = np.hstack([np.mean(mfccs, axis=1), np.std(mfccs, axis=1),\n",
    "                                       np.mean(spectral_bandwidth), np.std(spectral_bandwidth),\n",
    "                                       np.mean(spectral_centroid), np.std(spectral_centroid),\n",
    "                                       np.mean(spectral_contrast), np.std(spectral_contrast),\n",
    "                                       np.mean(zerocrossing_rate), np.std(zerocrossing_rate),\n",
    "                                       np.mean(spectral_rolloff), np.std(spectral_rolloff)])\n",
    "        \n",
    "        combined_features_for_CNN = np.hstack([spectral_bandwidth, spectral_centroid])\n",
    "        combined_features_for_CNN2= np.hstack([zerocrossing_rate, spectral_rolloff])\n",
    "        combined_features2=np.vstack([combined_features_for_CNN,combined_features_for_CNN2])\n",
    "\n",
    "        if model == \"KNN\":\n",
    "            features.append(combined_features)\n",
    "        else:\n",
    "            features.append(combined_features2)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "06f3f159",
   "metadata": {},
   "outputs": [],
   "source": [
    "features =extractFeatures(dataset,\"KNN\")\n",
    "features2 =extractFeatures(dataset,\"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4d269ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test=extractFeatures(dataset_test,\"KNN\")\n",
    "features_test2=extractFeatures(dataset_test,\"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fs = 44000\n",
    "# features=[]\n",
    "# features2=[]\n",
    "# f2=[]\n",
    "\n",
    "# for audio in dataset:\n",
    "#     mfcc = librosa.feature.mfcc(y=np.asarray(audio), sr=fs, n_mfcc=50)    \n",
    "#     # spectral spread\n",
    "#     spectral_bandwidth = librosa.feature.spectral_bandwidth(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "#     # spectral energy\n",
    "#     spectral_centroid = librosa.feature.spectral_centroid(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "#     # spectral density\n",
    "#     spectral_contrast = librosa.feature.spectral_contrast(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "#     #  rate of sign-changes in the signal\n",
    "#     zerocrossing_rate = librosa.feature.zero_crossing_rate(y=np.asarray(audio))\n",
    "\n",
    "#     #  frequency below which a certain percentage of the power spectrum is concentrated\n",
    "#     spectral_rolloff = librosa.feature.spectral_rolloff(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "#     combined_features = np.hstack([np.mean(mfcc, axis=1), np.std(mfcc, axis=1),\n",
    "#                                    np.mean(spectral_bandwidth), np.std(spectral_bandwidth),\n",
    "#                                    np.mean(spectral_centroid), np.std(spectral_centroid),\n",
    "#                                    np.mean(spectral_contrast), np.std(spectral_contrast),\n",
    "#                                    np.mean(zerocrossing_rate), np.std(zerocrossing_rate),\n",
    "#                                    np.mean(spectral_rolloff), np.std(spectral_rolloff)])\n",
    "    \n",
    "#     combined = np.hstack([spectral_bandwidth, spectral_centroid])\n",
    "#     combo= np.hstack([zerocrossing_rate, spectral_rolloff])\n",
    "#     co=np.vstack([combined,combo])\n",
    "#     f2.append(co)\n",
    "\n",
    "#     # #combined = np.concatenate(mfcc,spectral_bandwidth, spectral_centroid, spectral_contrast, zerocrossing_rate, spectral_rolloff)\n",
    "#     # x=spectral_bandwidth.shape\n",
    "\n",
    "#     combined_features_2d = combined_features.reshape(1, -1)\n",
    "\n",
    "#     # Append combined features as 2D array\n",
    "#     features.append(combined_features_2d)\n",
    "#     #features2.append(f2)\n",
    "\n",
    "#     #features.append(combined_features)\n",
    "#     features2.append(mfcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "705f2159",
   "metadata": {},
   "outputs": [],
   "source": [
    "features= np.asarray(features)\n",
    "features2= np.asarray(features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a09b0bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test= np.asarray(features_test)\n",
    "features_test2= np.asarray(features_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "251f99cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 110)\n",
      "(146, 2, 432)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(features2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af3a66b",
   "metadata": {},
   "source": [
    "Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # all\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# change is needed here: \n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03402f72",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "a3df585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "c2195ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_20 (Conv2D)          (None, 1, 431, 4)         20        \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 1724)              0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 16)                27600     \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,765\n",
      "Trainable params: 27,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (2, 432, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(4, kernel_size=(2,2), activation='relu', input_shape=input_shape))\n",
    "#model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "89feff4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 307.6995 - accuracy: 0.5603 - val_loss: 6.3601 - val_accuracy: 0.9667\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 180.7827 - accuracy: 0.5948 - val_loss: 410.0624 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 117.8740 - accuracy: 0.5603 - val_loss: 89.1423 - val_accuracy: 0.3333\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 33.5695 - accuracy: 0.6983 - val_loss: 102.1662 - val_accuracy: 0.2667\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 33.0934 - accuracy: 0.7241 - val_loss: 58.8267 - val_accuracy: 0.4333\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 31.3034 - accuracy: 0.6552 - val_loss: 96.5745 - val_accuracy: 0.2000\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 39.5289 - accuracy: 0.6034 - val_loss: 239.1017 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 44.2397 - accuracy: 0.6466 - val_loss: 63.0763 - val_accuracy: 0.4000\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 27.7999 - accuracy: 0.6810 - val_loss: 136.1225 - val_accuracy: 0.1667\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 120.3845 - accuracy: 0.6034 - val_loss: 101.5892 - val_accuracy: 0.2667\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=features2,y=labels,batch_size=5 ,epochs=10,validation_split=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "c3e8a020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "output= model.predict(features_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "7776344a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7142857142857143\n",
      "Precision: 0.6\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "predictions = [1 if x > 0.5 else 0 for x in output]\n",
    "\n",
    "accuracy2 = accuracy_score(labels_test, predictions)\n",
    "precision2 = precision_score(labels_test, predictions)\n",
    "recall2 = recall_score(labels_test, predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9759d590",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "0936b1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbour:\n",
      "Precision: 0.7619047619047619\n",
      "Recall: 0.8888888888888888\n",
      "CNN:\n",
      "Accuracy: 0.7142857142857143\n",
      "Precision: 0.6\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Nearest Neighbour:\")\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "print(\"CNN:\")\n",
    "print(\"Accuracy:\", accuracy2)\n",
    "print(\"Precision:\", precision2)\n",
    "print(\"Recall:\", recall2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
