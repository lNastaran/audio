{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35692416",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20043c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft,dct\n",
    "import librosa\n",
    "from scipy import signal\n",
    "import soundfile as sf\n",
    "from librosa.display import specshow\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e099d97",
   "metadata": {},
   "source": [
    "Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # separate \n",
    "\n",
    "carTrain = glob.glob(\"cars/train/*.wav\")\n",
    "carTest = glob.glob(\"cars/test/*.wav\")\n",
    "\n",
    "tramTrain = glob.glob(\"trams/train/*.wav\")\n",
    "tramTest = glob.glob(\"trams/test/*.wav\")\n",
    "\n",
    "dataset=[]\n",
    "labels = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importFiles(files, label):\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    for file in files:\n",
    "        data,sr = librosa.load(file)\n",
    "        data = librosa.effects.trim(data, top_db=20, frame_length=1024, hop_length=512)[0] \n",
    "        # print(data.size)\n",
    "        # print(data.shape)# Desired length in samples\n",
    "        desired_length = sr * 5\n",
    "        # # Initialize a new array of zeros with the desired length\n",
    "        fixed_length_data = np.zeros(desired_length)\n",
    "        #  Check the length of the original data\n",
    "        original_length = len(data)\n",
    "        # # If original data is longer than desired length, truncate it\n",
    "        # # If it is shorter, pad with zeros\n",
    "        if original_length > desired_length:\n",
    "            fixed_length_data = data[:desired_length]\n",
    "        else:\n",
    "            fixed_length_data[:original_length] = data\n",
    "        # # Now use fixed_length_data as your adjusted data\n",
    "        data = fixed_length_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        labels.append(label)\n",
    "        dataset.append(data)\n",
    "\n",
    "    return dataset,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_289696/3366563929.py:5: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  data,sr = librosa.load(file)\n",
      "/home/smitty/miniconda3/envs/audioproc/lib/python3.8/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "# # separate\n",
    "\n",
    "car_dataset, car_label  = importFiles(carTrain, 0)\n",
    "car_test_dataset, car_test_label = importFiles(carTest, 0)\n",
    "tram_dataset, tram_label = importFiles(tramTrain, 1)\n",
    "tram_test_dataset, tram_test_label = importFiles(tramTest, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tram_dataset_array = np.array(tram_dataset)\n",
    "car_dataset_array = np.array(car_dataset)\n",
    "tram_label_array = np.array(tram_label)\n",
    "car_label_array = np.array(car_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db950037",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.concatenate([tram_dataset, car_dataset], axis=0)\n",
    "labels = np.concatenate([tram_label, car_label], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4880df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = np.concatenate([tram_test_dataset,car_test_dataset], axis=0)\n",
    "labels_test = np.concatenate([tram_test_label, car_test_label], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9597e96a",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(data, target_height, target_width):\n",
    "    h = data.shape[0]\n",
    "    w = data.shape[1]\n",
    "    \n",
    "    a = max((target_height - h) // 2,0)\n",
    "    aa = max(0,target_height - a - h)\n",
    "    \n",
    "    b = max(0,(target_width - w) // 2)\n",
    "    bb = max(target_width - b - w,0)\n",
    "    \n",
    "    return np.pad(data, pad_width=((a, aa), (b, bb)), mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f78ff240",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 44000\n",
    "f2=[]\n",
    "\n",
    "def extractFeatures(dataset, model):\n",
    "    features = []\n",
    "    max_size = 1000\n",
    "    \n",
    "    for audio in dataset:\n",
    "        mfccs = librosa.feature.mfcc(y=np.asarray(audio), sr=fs, n_mfcc=50)\n",
    "        mfccs_scaled = np.mean(mfccs.T, axis=0).reshape((1,-1))\n",
    "    \n",
    "        # spectral spread\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "        # spectral energy\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "        # spectral density\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "        #  rate of sign-changes in the signal\n",
    "        zerocrossing_rate = librosa.feature.zero_crossing_rate(y=np.asarray(audio))\n",
    "\n",
    "        #  frequency below which a certain percentage of the power spectrum is concentrated\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "        if model == \"KNN1\":\n",
    "            # combined_features = np.hstack([np.mean(mfccs, axis=1), np.std(mfccs, axis=1),\n",
    "            #                            np.mean(spectral_bandwidth), np.std(spectral_bandwidth),\n",
    "            #                            np.mean(spectral_centroid), np.std(spectral_centroid),\n",
    "            #                            np.mean(spectral_contrast), np.std(spectral_contrast),\n",
    "            #                            np.mean(zerocrossing_rate), np.std(zerocrossing_rate),\n",
    "            #                            np.mean(spectral_rolloff), np.std(spectral_rolloff)])\n",
    "            \n",
    "            # combined features include spectral bandwidth, spectral centroid, zero-crossing rate, spectral rolloff\n",
    "            mfccs = np.reshape(mfccs, (1,-1))\n",
    "            spectral_contrast = np.reshape(spectral_contrast, (1,-1))\n",
    "            combined_features = np.hstack([spectral_bandwidth, spectral_centroid, zerocrossing_rate, spectral_rolloff, mfccs, spectral_contrast])\n",
    "            features.append(combined_features)\n",
    "        # elif model == \"KNN2\":\n",
    "        #     mfccs = np.reshape(mfccs, (1,-1))\n",
    "        #     spectral_contrast = np.reshape(spectral_contrast, (1,-1))\n",
    "        #     combined_features = np.hstack([spectral_bandwidth, zerocrossing_rate, spectral_rolloff, mfccs, spectral_contrast])\n",
    "            # features.append(combined_features)\n",
    "        else:\n",
    "            combined_features_for_CNN = np.hstack([spectral_bandwidth, spectral_centroid])\n",
    "            combined_features_for_CNN2= np.hstack([zerocrossing_rate, spectral_rolloff])\n",
    "            combined_features = np.vstack([combined_features_for_CNN,combined_features_for_CNN2])\n",
    "            \n",
    "            # combined_features = np.hstack([np.mean(mfccs, axis=1), np.std(mfccs, axis=1),\n",
    "            #                            np.mean(spectral_bandwidth), np.std(spectral_bandwidth),\n",
    "            #                            np.mean(spectral_centroid), np.std(spectral_centroid),\n",
    "            #                            np.mean(spectral_contrast), np.std(spectral_contrast),\n",
    "            #                            np.mean(zerocrossing_rate), np.std(zerocrossing_rate),\n",
    "            #                            np.mean(spectral_rolloff), np.std(spectral_rolloff)])\n",
    "            # spectral_contrast = np.reshape(spectral_contrast, (1,-1))\n",
    "            # combined_features = np.hstack([mfccs_scaled,\n",
    "            #                                spectral_bandwidth,\n",
    "            #                                spectral_centroid,\n",
    "            #                                zerocrossing_rate, \n",
    "            #                                spectral_rolloff,\n",
    "            #                                spectral_contrast])\n",
    "            # for i in range(0,mfccs.shape[0]):\n",
    "            #     combined_features = np.append(combined_features, padding(spectral_bandwidth, 1, max_size), axis=0)\n",
    "            #     combined_features = np.append(combined_features, padding(spectral_centroid, 1, max_size), axis=0)\n",
    "            #     combined_features = np.append(combined_features, padding(zerocrossing_rate, 1, max_size), axis=0)\n",
    "            #     combined_features = np.append(combined_features, padding(spectral_rolloff, 1, max_size), axis=0)\n",
    "            #     combined_features = np.append(combined_features, padding(spectral_contrast, 1, max_size), axis=0)\n",
    "            \n",
    "            #     if combined_features.shape[0] > mfccs.shape[0]:\n",
    "            #         difference = combined_features.shape[0] - mfccs.shape[0]\n",
    "            #         combined_features = combined_features[:-difference, :]\n",
    "            #         break\n",
    "                \n",
    "                \n",
    "            # combined_features = np.dstack((combined_features, padding(mfccs, mfccs.shape[0], max_size)))\n",
    "            \n",
    "            features.append(combined_features)\n",
    "\n",
    "    features = np.array(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "06f3f159",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = extractFeatures(dataset, \"KNN1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features2 = extractFeatures(dataset,\"KNN2\")\n",
    "features2 = extractFeatures(dataset,\"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n",
      "146\n"
     ]
    }
   ],
   "source": [
    "# print(len(features))\n",
    "# print(len(features2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4d269ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = extractFeatures(dataset_test,\"KNN1\")\n",
    "# features_test2 = extractFeatures(dataset_test,\"KNN2\")\n",
    "features_test2=extractFeatures(dataset_test,\"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fs = 44000\n",
    "# features=[]\n",
    "# features2=[]\n",
    "# f2=[]\n",
    "\n",
    "# for audio in dataset:\n",
    "#     mfcc = librosa.feature.mfcc(y=np.asarray(audio), sr=fs, n_mfcc=50)    \n",
    "#     # spectral spread\n",
    "#     spectral_bandwidth = librosa.feature.spectral_bandwidth(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "#     # spectral energy\n",
    "#     spectral_centroid = librosa.feature.spectral_centroid(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "#     # spectral density\n",
    "#     spectral_contrast = librosa.feature.spectral_contrast(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "#     #  rate of sign-changes in the signal\n",
    "#     zerocrossing_rate = librosa.feature.zero_crossing_rate(y=np.asarray(audio))\n",
    "\n",
    "#     #  frequency below which a certain percentage of the power spectrum is concentrated\n",
    "#     spectral_rolloff = librosa.feature.spectral_rolloff(y=np.asarray(audio), sr=fs)\n",
    "\n",
    "#     combined_features = np.hstack([np.mean(mfcc, axis=1), np.std(mfcc, axis=1),\n",
    "#                                    np.mean(spectral_bandwidth), np.std(spectral_bandwidth),\n",
    "#                                    np.mean(spectral_centroid), np.std(spectral_centroid),\n",
    "#                                    np.mean(spectral_contrast), np.std(spectral_contrast),\n",
    "#                                    np.mean(zerocrossing_rate), np.std(zerocrossing_rate),\n",
    "#                                    np.mean(spectral_rolloff), np.std(spectral_rolloff)])\n",
    "    \n",
    "#     combined = np.hstack([spectral_bandwidth, spectral_centroid])\n",
    "#     combo= np.hstack([zerocrossing_rate, spectral_rolloff])\n",
    "#     co=np.vstack([combined,combo])\n",
    "#     f2.append(co)\n",
    "\n",
    "#     # #combined = np.concatenate(mfcc,spectral_bandwidth, spectral_centroid, spectral_contrast, zerocrossing_rate, spectral_rolloff)\n",
    "#     # x=spectral_bandwidth.shape\n",
    "\n",
    "#     combined_features_2d = combined_features.reshape(1, -1)\n",
    "\n",
    "#     # Append combined features as 2D array\n",
    "#     features.append(combined_features_2d)\n",
    "#     #features2.append(f2)\n",
    "\n",
    "#     #features.append(combined_features)\n",
    "#     features2.append(mfcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "251f99cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 1, 13176)\n",
      "(146, 110)\n",
      "(36, 1, 13176)\n",
      "(36, 110)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(features2.shape)\n",
    "\n",
    "print(features_test.shape)\n",
    "print(features_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 13176)\n"
     ]
    }
   ],
   "source": [
    "features_knn = features.reshape((features.shape[0],-1))\n",
    "# features_cnn = features2.reshape((features2.shape[0],-1))\n",
    "\n",
    "print(features_knn.shape)\n",
    "# print(features_cnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test_knn = features_test.reshape((features_test.shape[0],-1))\n",
    "# features_test_cnn = features_test2.reshape((features_test2.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 13176)\n"
     ]
    }
   ],
   "source": [
    "print(features_test_knn.shape)\n",
    "# print(features_test_cnn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af3a66b",
   "metadata": {},
   "source": [
    "Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7647058823529411\n",
      "0.8125\n",
      "0.8055555555555556\n"
     ]
    }
   ],
   "source": [
    "# # first knn\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(features_knn, labels)\n",
    "\n",
    "y_pred = knn.predict(features_test_knn)\n",
    "\n",
    "precision = precision_score(labels_test, y_pred)\n",
    "recall = recall_score(labels_test, y_pred)\n",
    "accuracy = accuracy_score(labels_test, y_pred)\n",
    "\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6190476190476191\n",
      "0.8125\n",
      "0.6944444444444444\n"
     ]
    }
   ],
   "source": [
    "# # X_train2, X_test2, y_train2, y_test2 = train_test_split(features3, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# knn2 = KNeighborsClassifier(n_neighbors=1)\n",
    "# knn2.fit(features_knn2, labels)\n",
    "\n",
    "# y_pred2 = knn2.predict(features_test_knn2)\n",
    "\n",
    "# precision2 = precision_score(labels_test, y_pred2)\n",
    "# recall2 = recall_score(labels_test, y_pred2)\n",
    "# accuracy2 = accuracy_score(labels_test, y_pred2)\n",
    "\n",
    "# print(precision2)\n",
    "# print(recall2)\n",
    "# print(accuracy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03402f72",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a3df585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c2195ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 1, 431, 4)         20        \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1724)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                27600     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27765 (108.46 KB)\n",
      "Trainable params: 27765 (108.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## original model\n",
    "input_shape = (2, 432, 1)\n",
    "# input_shape = (50,1000,1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(4, kernel_size=(2,2), activation='relu', input_shape=input_shape))\n",
    "#model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_16 (Conv2D)          (None, 48, 998, 32)       608       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 24, 499, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 24, 499, 32)       0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 22, 497, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 11, 248, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 11, 248, 64)       0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 9, 246, 32)        18464     \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 70848)             0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 64)                4534336   \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4574801 (17.45 MB)\n",
      "Trainable params: 4574801 (17.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## alternative model\n",
    "input_shape = (50,1000,2)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(24, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features2, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "89feff4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 3s 29ms/step - loss: 214.4597 - accuracy: 0.6121 - val_loss: 32.8214 - val_accuracy: 0.4333\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 95.0210 - accuracy: 0.5948 - val_loss: 484.6587 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 100.6553 - accuracy: 0.6552 - val_loss: 8.2901 - val_accuracy: 0.8667\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 35.3903 - accuracy: 0.7069 - val_loss: 23.9492 - val_accuracy: 0.7000\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 41.5757 - accuracy: 0.6638 - val_loss: 58.5651 - val_accuracy: 0.4333\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 32.0459 - accuracy: 0.6810 - val_loss: 11.8131 - val_accuracy: 0.8000\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 18.2898 - accuracy: 0.8276 - val_loss: 45.5211 - val_accuracy: 0.4333\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 20.5235 - accuracy: 0.7500 - val_loss: 36.0324 - val_accuracy: 0.5667\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 18.2755 - accuracy: 0.7931 - val_loss: 111.0680 - val_accuracy: 0.0667\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 26.6826 - accuracy: 0.7586 - val_loss: 25.4137 - val_accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=features2,y=labels,batch_size=5,epochs=10,validation_split=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c3e8a020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "output= model.predict(features_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7776344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "predictions = [1 if x > 0.5 else 0 for x in output]\n",
    "\n",
    "accuracy2 = accuracy_score(labels_test, predictions)\n",
    "precision2 = precision_score(labels_test, predictions)\n",
    "recall2 = recall_score(labels_test, predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9759d590",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0936b1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbour:\n",
      "Accuracy: 0.8055555555555556\n",
      "Precision: 0.7647058823529411\n",
      "Recall: 0.8125\n",
      "CNN:\n",
      "Accuracy: 0.8888888888888888\n",
      "Precision: 0.8\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Nearest Neighbour:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "print(\"CNN:\")\n",
    "print(\"Accuracy:\", accuracy2)\n",
    "print(\"Precision:\", precision2)\n",
    "print(\"Recall:\", recall2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
